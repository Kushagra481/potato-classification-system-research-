{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6978893,"sourceType":"datasetVersion","datasetId":4010347}],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Install necessary packages","metadata":{"id":"aiL5ryEGryF7","outputId":"e40e9c65-db2b-428f-e535-116417cfed13"}},{"cell_type":"code","source":"!pip install torchsampler\n!pip install torchmetrics\n!pip install split-folders","metadata":{"id":"vdMIT3fF2GoK","executionInfo":{"status":"ok","timestamp":1730090638763,"user_tz":-330,"elapsed":10203,"user":{"displayName":"Varun Menon","userId":"16749211396894445614"}},"outputId":"03a2b877-57ca-491c-b8e3-cecb62b356c0","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:33:13.439654Z","iopub.execute_input":"2024-12-18T19:33:13.440016Z","iopub.status.idle":"2024-12-18T19:33:38.911779Z","shell.execute_reply.started":"2024-12-18T19:33:13.439974Z","shell.execute_reply":"2024-12-18T19:33:38.910392Z"}},"outputs":[{"name":"stdout","text":"Collecting torchsampler\n  Downloading torchsampler-0.1.2-py3-none-any.whl.metadata (4.7 kB)\nRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.10/site-packages (from torchsampler) (2.4.0)\nRequirement already satisfied: torchvision>=0.5 in /opt/conda/lib/python3.10/site-packages (from torchsampler) (0.19.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from torchsampler) (2.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->torchsampler) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->torchsampler) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->torchsampler) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->torchsampler) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->torchsampler) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->torchsampler) (2024.6.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5->torchsampler) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5->torchsampler) (10.3.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->torchsampler) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->torchsampler) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->torchsampler) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->torchsampler) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.3->torchsampler) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.3->torchsampler) (1.3.0)\nDownloading torchsampler-0.1.2-py3-none-any.whl (5.6 kB)\nInstalling collected packages: torchsampler\nSuccessfully installed torchsampler-0.1.2\nRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.4.2)\nRequirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.26.4)\nRequirement already satisfied: packaging>17.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (21.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.4.0)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.11.7)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (70.0.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>17.1->torchmetrics) (3.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.15.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\nCollecting split-folders\n  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\nDownloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\nInstalling collected packages: split-folders\nSuccessfully installed split-folders-0.5.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"#  2. Import required libraries","metadata":{"id":"vnN5WLYW2GoL"}},{"cell_type":"code","source":"import os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:33:38.914102Z","iopub.execute_input":"2024-12-18T19:33:38.914457Z","iopub.status.idle":"2024-12-18T19:33:38.918944Z","shell.execute_reply.started":"2024-12-18T19:33:38.914424Z","shell.execute_reply":"2024-12-18T19:33:38.918028Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import torchvision\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport os\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom tqdm import tqdm\nfrom PIL import Image\nimport torchvision.models as models\nfrom torch.cuda.amp import autocast, GradScaler\nfrom tqdm.autonotebook import tqdm, trange\nimport time\nfrom sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,confusion_matrix, classification_report\nfrom torchsampler import ImbalancedDatasetSampler\nfrom torch.utils.data.sampler import BatchSampler\nimport pandas as pd\nimport random\nimport torch\nfrom torch.autograd import Variable\nfrom torch.nn import Linear, ReLU, LeakyReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n!jupyter nbextension enable --py widgetsnbextension\n!jupyter nbextension install --py widgetsnbextension","metadata":{"id":"GEPF5Hprr1k1","outputId":"5b1095da-32d6-465f-8e1e-5ee8e2209460","executionInfo":{"status":"error","timestamp":1730094107195,"user_tz":-330,"elapsed":15065,"user":{"displayName":"Varun Menon","userId":"16749211396894445614"}},"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:33:38.920178Z","iopub.execute_input":"2024-12-18T19:33:38.920532Z","iopub.status.idle":"2024-12-18T19:33:46.179669Z","shell.execute_reply.started":"2024-12-18T19:33:38.920494Z","shell.execute_reply":"2024-12-18T19:33:46.178730Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_82/1163429827.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm, trange\n","output_type":"stream"},{"name":"stdout","text":"Enabling notebook extension jupyter-js-widgets/extension...\n      - Validating: \u001b[32mOK\u001b[0m\nInstalling /opt/conda/lib/python3.10/site-packages/widgetsnbextension/static -> jupyter-js-widgets\nMaking directory: /usr/local/share/jupyter/nbextensions/jupyter-js-widgets/\nCopying: /opt/conda/lib/python3.10/site-packages/widgetsnbextension/static/extension.js -> /usr/local/share/jupyter/nbextensions/jupyter-js-widgets/extension.js\nCopying: /opt/conda/lib/python3.10/site-packages/widgetsnbextension/static/extension.js.map -> /usr/local/share/jupyter/nbextensions/jupyter-js-widgets/extension.js.map\n- Validating: \u001b[32mOK\u001b[0m\n\n    To initialize this nbextension in the browser every time the notebook (or other app) loads:\n    \n          jupyter nbextension enable widgetsnbextension --py\n    \n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# 3. Data Pre-processing","metadata":{"id":"to0LoSj62GoM"}},{"cell_type":"code","source":"import splitfolders\n\n# Split the dataset into train, test, and val folders\nsplitfolders.ratio('/kaggle/input/potato-leaf-disease-dataset/Potato Leaf Disease Dataset in Uncontrolled Environment', output=\"data1\", seed=1337, ratio=(.7, 0.2, 0.1))\n\n# Define the paths to train, test, and val folders\ntrain_folder = \"data1/train\"\ntest_folder = \"data1/test\"\nval_folder = \"data1/val\"\n","metadata":{"id":"aPyKTCiJ2GoM","executionInfo":{"status":"error","timestamp":1730094085568,"user_tz":-330,"elapsed":831,"user":{"displayName":"Varun Menon","userId":"16749211396894445614"}},"outputId":"7c258e6b-faaa-406e-b9fa-c6868fa820b3","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:33:46.181086Z","iopub.execute_input":"2024-12-18T19:33:46.181761Z","iopub.status.idle":"2024-12-18T19:34:05.854437Z","shell.execute_reply.started":"2024-12-18T19:33:46.181732Z","shell.execute_reply":"2024-12-18T19:34:05.853591Z"}},"outputs":[{"name":"stderr","text":"Copying files: 3076 files [00:19, 156.50 files/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"**Data Augmentation**","metadata":{"id":"sk6V0zjt2GoM"}},{"cell_type":"markdown","source":"\ntrain_transforms = transforms.Compose([\n                                       transforms.Resize((256,256)),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.RandomRotation(90),\n                                       transforms.ToTensor(),\n\n])\n\nval_transforms = transforms.Compose([\n                                       transforms.Resize((256,256)),\n                                       transforms.RandomHorizontalFlip(),\n                                       transforms.RandomRotation(90),\n                                       transforms.ToTensor(),\n\n])\n\ntest_transforms = transforms.Compose([\n                                       transforms.Resize((256,256)),\n                                       transforms.ToTensor(),\n\n])","metadata":{"id":"p5FduGFbUH64","execution":{"iopub.status.busy":"2024-12-18T18:26:45.305443Z","iopub.execute_input":"2024-12-18T18:26:45.305707Z","iopub.status.idle":"2024-12-18T18:26:45.311680Z","shell.execute_reply.started":"2024-12-18T18:26:45.305682Z","shell.execute_reply":"2024-12-18T18:26:45.310884Z"}}},{"cell_type":"code","source":"from torchvision import transforms\n\n# Training Data Transforms\ntrain_transforms = transforms.Compose([\n    transforms.Resize((256, 256)),            # Resizing to 256x256\n    transforms.RandomHorizontalFlip(),        # Random horizontal flipping\n    transforms.RandomRotation(90),            # Random rotation\n    transforms.ToTensor(),                    # Convert to Tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                         std=[0.229, 0.224, 0.225])  # Normalize for VGG16\n])\n\n# Validation Data Transforms\nval_transforms = transforms.Compose([\n    transforms.Resize((256, 256)),            # Resizing to 256x256\n    transforms.ToTensor(),                    # Convert to Tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                         std=[0.229, 0.224, 0.225])  # Normalize for VGG16\n])\n\n# Test Data Transforms\ntest_transforms = transforms.Compose([\n    transforms.Resize((256, 256)),            # Resizing to 256x256\n    transforms.ToTensor(),                    # Convert to Tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                         std=[0.229, 0.224, 0.225])  # Normalize for VGG16\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:34:05.855839Z","iopub.execute_input":"2024-12-18T19:34:05.856475Z","iopub.status.idle":"2024-12-18T19:34:05.863599Z","shell.execute_reply.started":"2024-12-18T19:34:05.856432Z","shell.execute_reply":"2024-12-18T19:34:05.862766Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# **4. Create data loaders**","metadata":{"id":"FEzNUtCP2GoM"}},{"cell_type":"code","source":"train_dataset = torchvision.datasets.ImageFolder(root = train_folder, transform=train_transforms)\nval_dataset = torchvision.datasets.ImageFolder(root = val_folder, transform=val_transforms)\ntest_dataset = torchvision.datasets.ImageFolder(root = test_folder, transform=test_transforms)","metadata":{"id":"CcP3xZGQUK69","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:34:05.864620Z","iopub.execute_input":"2024-12-18T19:34:05.864930Z","iopub.status.idle":"2024-12-18T19:34:05.886083Z","shell.execute_reply.started":"2024-12-18T19:34:05.864904Z","shell.execute_reply":"2024-12-18T19:34:05.885306Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(dataset = train_dataset, sampler=ImbalancedDatasetSampler(train_dataset), batch_size=16)\nval_loader = torch.utils.data.DataLoader(dataset = val_dataset, batch_size=16, shuffle=False)\ntest_loader = torch.utils.data.DataLoader(dataset = test_dataset, batch_size=16, shuffle=False)","metadata":{"id":"ncQxo4bFUQVq","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:34:05.888955Z","iopub.execute_input":"2024-12-18T19:34:05.889194Z","iopub.status.idle":"2024-12-18T19:34:05.927970Z","shell.execute_reply.started":"2024-12-18T19:34:05.889171Z","shell.execute_reply":"2024-12-18T19:34:05.927159Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"id":"FgoSUGEzUUKF","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:34:05.928927Z","iopub.execute_input":"2024-12-18T19:34:05.929163Z","iopub.status.idle":"2024-12-18T19:34:05.992462Z","shell.execute_reply.started":"2024-12-18T19:34:05.929139Z","shell.execute_reply":"2024-12-18T19:34:05.991579Z"}},"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# **5. Model definition**","metadata":{"id":"xDkGjA4z2GoN"}},{"cell_type":"code","source":"model = models.densenet121(pretrained=True)\nprint(model)","metadata":{"id":"WoTS8vMjUXew","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:34:05.993560Z","iopub.execute_input":"2024-12-18T19:34:05.993863Z","iopub.status.idle":"2024-12-18T19:34:06.654152Z","shell.execute_reply.started":"2024-12-18T19:34:05.993837Z","shell.execute_reply":"2024-12-18T19:34:06.653298Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to /root/.cache/torch/hub/checkpoints/densenet121-a639ec97.pth\n100%|██████████| 30.8M/30.8M [00:00<00:00, 153MB/s] ","output_type":"stream"},{"name":"stdout","text":"DenseNet(\n  (features): Sequential(\n    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu0): ReLU(inplace=True)\n    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (denseblock1): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition1): _Transition(\n      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock2): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition2): _Transition(\n      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock3): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer13): _DenseLayer(\n        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer14): _DenseLayer(\n        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer15): _DenseLayer(\n        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer16): _DenseLayer(\n        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer17): _DenseLayer(\n        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer18): _DenseLayer(\n        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer19): _DenseLayer(\n        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer20): _DenseLayer(\n        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer21): _DenseLayer(\n        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer22): _DenseLayer(\n        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer23): _DenseLayer(\n        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer24): _DenseLayer(\n        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (transition3): _Transition(\n      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n    )\n    (denseblock4): _DenseBlock(\n      (denselayer1): _DenseLayer(\n        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer2): _DenseLayer(\n        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer3): _DenseLayer(\n        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer4): _DenseLayer(\n        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer5): _DenseLayer(\n        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer6): _DenseLayer(\n        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer7): _DenseLayer(\n        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer8): _DenseLayer(\n        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer9): _DenseLayer(\n        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer10): _DenseLayer(\n        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer11): _DenseLayer(\n        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer12): _DenseLayer(\n        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer13): _DenseLayer(\n        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer14): _DenseLayer(\n        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer15): _DenseLayer(\n        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n      (denselayer16): _DenseLayer(\n        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu1): ReLU(inplace=True)\n        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu2): ReLU(inplace=True)\n        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      )\n    )\n    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (classifier): Linear(in_features=1024, out_features=1000, bias=True)\n)\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"# **6. Modifying the Classifier**","metadata":{"id":"FKG_If6E2GoN"}},{"cell_type":"code","source":"# Modify the classifier for 4 output classes\nnum_classes = 7 # Adjust to your dataset\nmodel.classifier = nn.Linear(model.classifier.in_features, num_classes)","metadata":{"id":"jQwtecEgVIAd","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:34:06.655327Z","iopub.execute_input":"2024-12-18T19:34:06.655747Z","iopub.status.idle":"2024-12-18T19:34:06.661187Z","shell.execute_reply.started":"2024-12-18T19:34:06.655703Z","shell.execute_reply":"2024-12-18T19:34:06.660242Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# **7. Loss function and optimizer**","metadata":{"id":"tZfSZnn22GoN"}},{"cell_type":"code","source":"\nif torch.cuda.is_available() == True:\n    model = model.cuda()\nelse:\n    model = model\ncriterion = torch.nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\nscaler = GradScaler(enabled=True)\nuse_cuda = True","metadata":{"id":"52qYFHQlVNoM","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:34:06.662468Z","iopub.execute_input":"2024-12-18T19:34:06.662825Z","iopub.status.idle":"2024-12-18T19:34:06.878694Z","shell.execute_reply.started":"2024-12-18T19:34:06.662789Z","shell.execute_reply":"2024-12-18T19:34:06.877798Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_82/163793647.py:8: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = GradScaler(enabled=True)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# **8. Training and testing functions**","metadata":{"id":"8ZCFfKF82GoO"}},{"cell_type":"code","source":"train_accu = []\ntraining_loss = []\n\ndef train(model, iterator, optimizer, criterion, device):\n\n    epoch_loss = 0\n    epoch_acc = 0\n    image_preds_all = []\n    image_targets_all = []\n\n    model.train()\n\n    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n\n        x = x.to(device).float()\n        y = y.to(device).long()\n\n        with autocast():\n\n            y_pred = model(x)\n\n            image_preds_all += [torch.argmax(y_pred, 1).detach().cpu().numpy()]\n            image_targets_all += [y.detach().cpu().numpy()]\n\n            loss = criterion(y_pred, y)\n\n            acc = calculate_accuracy(y_pred, y)\n\n            scaler.scale(loss).backward()\n            #torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n\n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n    image_preds_all = np.concatenate(image_preds_all)\n    image_targets_all = np.concatenate(image_targets_all)\n    score = (image_preds_all==image_targets_all).mean()\n\n    train_losss = epoch_loss / len(iterator)\n\n    train_accu.append(score*100)\n    training_loss.append(train_losss)\n\n    #print(score)\n    #print(len(train_accu), len(training_loss))\n\n    return epoch_loss / len(iterator), epoch_acc / len(iterator), train_accu, training_loss","metadata":{"id":"fFHAPeLoVWEh","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:34:06.879942Z","iopub.execute_input":"2024-12-18T19:34:06.880629Z","iopub.status.idle":"2024-12-18T19:34:06.888520Z","shell.execute_reply.started":"2024-12-18T19:34:06.880582Z","shell.execute_reply":"2024-12-18T19:34:06.887712Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"val_accu = []\neval_loss = []\n\ndef evaluate(model, iterator, criterion, device):\n\n    epoch_loss = 0\n    epoch_acc = 0\n    image_preds_all = []\n    image_targets_all = []\n\n    model.eval()\n\n    with torch.no_grad():\n\n        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n\n            x = x.to(device).float()\n            y = y.to(device).long()\n\n            y_pred = model(x)\n\n            image_preds_all += [torch.argmax(y_pred, 1).detach().cpu().numpy()]\n            image_targets_all += [y.detach().cpu().numpy()]\n\n            loss = criterion(y_pred, y)\n\n            acc = calculate_accuracy(y_pred, y)\n\n            epoch_loss += loss.item()\n            epoch_acc += acc.item()\n\n    image_preds_all = np.concatenate(image_preds_all)\n    image_targets_all = np.concatenate(image_targets_all)\n    score = (image_preds_all==image_targets_all).mean()\n\n    val_losss = epoch_loss / len(iterator)\n\n    val_accu.append(score*100)\n    eval_loss.append(val_losss)\n\n    performance_matrix(image_targets_all, image_preds_all)\n\n    return epoch_loss / len(iterator), epoch_acc / len(iterator), val_accu, eval_loss","metadata":{"id":"l9bxrvlEVY0Z","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:34:06.889779Z","iopub.execute_input":"2024-12-18T19:34:06.890361Z","iopub.status.idle":"2024-12-18T19:34:06.900163Z","shell.execute_reply.started":"2024-12-18T19:34:06.890333Z","shell.execute_reply":"2024-12-18T19:34:06.899384Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def performance_matrix(true,pred):\n    precision = precision_score(true,pred,average='macro')\n    recall = recall_score(true,pred,average='macro')\n    accuracy = accuracy_score(true,pred)\n    f1_sco = f1_score(true,pred,average='macro')\n    print('Precision: {:.4f} Recall: {:.4f}, Accuracy: {:.4f}: ,f1_score: {:.4f}'.format(precision,recall,accuracy,f1_sco))\n    print('Classification Report:\\n',classification_report(true, pred))","metadata":{"id":"QTgu-yll2GoO","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:34:06.901201Z","iopub.execute_input":"2024-12-18T19:34:06.901901Z","iopub.status.idle":"2024-12-18T19:34:06.913002Z","shell.execute_reply.started":"2024-12-18T19:34:06.901863Z","shell.execute_reply":"2024-12-18T19:34:06.912263Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def calculate_accuracy(y_pred, y):\n    top_pred = y_pred.argmax(1, keepdim=True)\n    correct = top_pred.eq(y.view_as(top_pred)).sum()\n    acc = correct.float() / y.shape[0]\n    return acc","metadata":{"id":"30FyLWx-2GoO","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:34:06.913960Z","iopub.execute_input":"2024-12-18T19:34:06.914279Z","iopub.status.idle":"2024-12-18T19:34:06.924435Z","shell.execute_reply.started":"2024-12-18T19:34:06.914249Z","shell.execute_reply":"2024-12-18T19:34:06.923606Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def epoch_time(start_time, end_time):\n    elapsed_time = end_time - start_time\n    elapsed_mins = int(elapsed_time / 60)\n    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs","metadata":{"id":"dEOVgoaXVc7c","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:34:06.925633Z","iopub.execute_input":"2024-12-18T19:34:06.925963Z","iopub.status.idle":"2024-12-18T19:34:06.932808Z","shell.execute_reply.started":"2024-12-18T19:34:06.925935Z","shell.execute_reply":"2024-12-18T19:34:06.932034Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def checkpoint_model(epoch, model, opt, best_val_acc, model_path):\n    model_state_dict = model.state_dict() if (device.type == 'cuda') else model.state_dict()\n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model_state_dict,\n        'opt_state_dict': opt.state_dict(),\n        'best_val_acc': best_val_acc\n    }, model_path)","metadata":{"id":"XtuWwUiTVfzP","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:34:06.933887Z","iopub.execute_input":"2024-12-18T19:34:06.934216Z","iopub.status.idle":"2024-12-18T19:34:06.940365Z","shell.execute_reply.started":"2024-12-18T19:34:06.934189Z","shell.execute_reply":"2024-12-18T19:34:06.939682Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def load_ckp(checkpoint_fpath, model, optimizer):\n    checkpoint = torch.load(checkpoint_fpath)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    optimizer.load_state_dict(checkpoint['opt_state_dict'])\n    return model, optimizer, checkpoint['epoch']","metadata":{"id":"Y-_eiY2rVlNW","trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:34:06.941209Z","iopub.execute_input":"2024-12-18T19:34:06.941440Z","iopub.status.idle":"2024-12-18T19:34:06.953718Z","shell.execute_reply.started":"2024-12-18T19:34:06.941417Z","shell.execute_reply":"2024-12-18T19:34:06.952822Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# **9. Training and validating the model**","metadata":{"id":"Wu8AXYib2GoO"}},{"cell_type":"markdown","source":"EPOCHS = 50\n\nbest_valid_loss = float('inf')\nbest_val_acc = 0.\n\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'The model has {count_parameters(model):,} trainable parameters')\n\ntrain_acc_gr = []\ntrain_loss_gr = []\nval_acc_gr = []\nval_loss_gr = []\n\nfor epoch in trange(EPOCHS, desc=\"Epochs\"):\n\n    start_time = time.monotonic()\n\n    train_loss, train_acc, train_acc_gr, train_loss_gr = train(model, train_loader, optimizer, criterion, device)\n    valid_loss, valid_acc, val_acc_gr, val_loss_gr = evaluate(model, val_loader, criterion, device)\n\n    if epoch % 30 == 0:\n        checkpoint_model(epoch, model, optimizer, best_val_acc, '/kaggle/working/CNN_epoch%d.pth' % epoch)\n\n\n    end_time = time.monotonic()\n\n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n\n    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n\n\nplt.plot(train_acc_gr,'-o')\nplt.plot(val_acc_gr,'-o')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend(['Train','Valid'])\nplt.title('Train vs Valid Accuracy')\nplt.show()\n\nplt.plot(train_loss_gr,'-o')\nplt.plot(val_loss_gr,'-o')\nplt.xlabel('epoch')\nplt.ylabel('losses')\nplt.legend(['Train','Valid'])\nplt.title('Train vs Valid Losses')\nplt.show()","metadata":{"id":"XczC7kpKVm-a","_kg_hide-output":true}},{"cell_type":"code","source":"import os\nimport time\nimport torch\nimport torch.nn.functional as F\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom tqdm import trange\n\nEPOCHS = 20\nPATIENCE = 10  # Number of epochs to wait before early stopping\nBATCH_SIZE = 16\nbest_valid_loss = float('inf')\nbest_val_acc = 0.\nepochs_no_improve = 0  # Counter for early stopping\n\n# 1. **Count Parameters in AlexNet**\ndef count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f'The model has {count_parameters(model):,} trainable parameters')\n\ntrain_acc_gr = []\ntrain_loss_gr = []\nval_acc_gr = []\nval_loss_gr = []\n\n# 2. **Optimizing Learning Rate and Weight Decay**\noptimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=1e-5)\n\n# 3. **Learning Rate Scheduler**\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n\n# 4. **Fine-Tune Selected Layers (if using a pretrained AlexNet)**\nfor param in model.parameters():\n    param.requires_grad = False  # Freeze all layers initially\n\n# Unfreeze specific layers for fine-tuning\nfor param in model.classifier.parameters():\n    param.requires_grad = True\n\n# Training Loop with Early Stopping\nfor epoch in trange(EPOCHS, desc=\"Epochs\"):\n    start_time = time.monotonic()\n\n    # 5. **Training Step**\n    train_loss, train_acc, train_acc_gr, train_loss_gr = train(model, train_loader, optimizer, criterion, device)\n    \n    # 6. **Validation Step**\n    valid_loss, valid_acc, val_acc_gr, val_loss_gr = evaluate(model, val_loader, criterion, device)\n    \n    # Update scheduler based on validation loss\n    scheduler.step(valid_loss)\n\n    # Check for improvement\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        best_val_acc = valid_acc\n        epochs_no_improve = 0  # Reset counter if validation improves\n    else:\n        epochs_no_improve += 1\n\n    # Early stopping check\n    if epochs_no_improve >= PATIENCE:\n        print(f'Early stopping at epoch {epoch+1} due to no improvement in validation loss/accuracy.')\n        break\n\n    # Save model checkpoint every 30 epochs\n    if epoch % 30 == 0:\n        checkpoint_model(epoch, model, optimizer, best_val_acc, '/kaggle/working/CNN_epoch%d.pth' % epoch)\n\n    end_time = time.monotonic()\n    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n\n    # Print metrics for each epoch\n    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n\n# Plot training and validation accuracy and loss\nplt.plot(train_acc_gr, '-o')\nplt.plot(val_acc_gr, '-o')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend(['Train', 'Valid'])\nplt.title('Train vs Valid Accuracy')\nplt.show()\n\nplt.plot(train_loss_gr, '-o')\nplt.plot(val_loss_gr, '-o')\nplt.xlabel('epoch')\nplt.ylabel('losses')\nplt.legend(['Train', 'Valid'])\nplt.title('Train vs Valid Losses')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-18T19:34:06.954938Z","iopub.execute_input":"2024-12-18T19:34:06.955370Z"}},"outputs":[{"name":"stdout","text":"The model has 6,961,031 trainable parameters\n","output_type":"stream"},{"name":"stderr","text":"Epochs:   0%|          | 0/20 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/135 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_82/3724402198.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/39 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Epochs:   5%|▌         | 1/20 [01:17<24:23, 77.04s/it]","output_type":"stream"},{"name":"stdout","text":"Precision: 0.3857 Recall: 0.3037, Accuracy: 0.2500: ,f1_score: 0.2420\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.38      0.42      0.40       113\n           1       0.38      0.08      0.13       149\n           2       0.27      0.33      0.29        40\n           3       0.26      0.46      0.33        13\n           4       0.27      0.31      0.29       122\n           5       0.15      0.52      0.23        69\n           6       1.00      0.01      0.02       106\n\n    accuracy                           0.25       612\n   macro avg       0.39      0.30      0.24       612\nweighted avg       0.43      0.25      0.22       612\n\nEpoch: 01 | Epoch Time: 1m 17s\n\tTrain Loss: 1.879 | Train Acc: 23.81%\n\t Val. Loss: 1.869 |  Val. Acc: 24.52%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/135 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_82/3724402198.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Evaluating:   0%|          | 0/39 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"Epochs:  10%|█         | 2/20 [02:32<22:48, 76.03s/it]","output_type":"stream"},{"name":"stdout","text":"Precision: 0.4028 Recall: 0.4394, Accuracy: 0.4167: ,f1_score: 0.3885\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.50      0.77      0.61       113\n           1       0.46      0.48      0.47       149\n           2       0.28      0.38      0.32        40\n           3       0.35      0.62      0.44        13\n           4       0.35      0.17      0.23       122\n           5       0.29      0.48      0.36        69\n           6       0.59      0.19      0.29       106\n\n    accuracy                           0.42       612\n   macro avg       0.40      0.44      0.39       612\nweighted avg       0.43      0.42      0.39       612\n\nEpoch: 02 | Epoch Time: 1m 15s\n\tTrain Loss: 1.719 | Train Acc: 41.23%\n\t Val. Loss: 1.704 |  Val. Acc: 41.83%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training:   0%|          | 0/135 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"27234a7eb3ba417389adbef88b612f54"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_82/3724402198.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with autocast():\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"# **10. Testing the model**","metadata":{"id":"Tdhk9UZD2GoP"}},{"cell_type":"code","source":"epoch_loss = 0\nepoch_acc = 0\nimage_preds_all = []\nimage_targets_all = []\n\nmodel.eval()\n\nwith torch.no_grad():\n\n    for (x, y) in tqdm(val_loader, desc=\"Evaluating\", leave=False):\n\n        x = x.to(device).float()\n        y = y.to(device).long()\n\n        y_pred = model(x)\n\n        image_preds_all += [torch.argmax(y_pred, 1).detach().cpu().numpy()]\n        image_targets_all += [y.detach().cpu().numpy()]\n\n        loss = criterion(y_pred, y)\n\n        acc = calculate_accuracy(y_pred, y)\n\n        epoch_loss += loss.item()\n        epoch_acc += acc.item()\n\nimage_preds_all = np.concatenate(image_preds_all)\nimage_targets_all = np.concatenate(image_targets_all)\nscore = (image_preds_all==image_targets_all).mean()\n\nperformance_matrix(image_targets_all, image_preds_all)","metadata":{"id":"8nCiFEl4WzvE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\n\ndef predict_image(image_path, model, transform, device):\n    # Load the image\n    image = Image.open(image_path).convert('RGB')\n\n    # Apply the same transformations as used during training\n    image = transform(image).unsqueeze(0)  # Add batch dimension\n\n    # Move the image to the device (GPU/CPU)\n    image = image.to(device)\n\n    # Set the model to evaluation mode\n    model.eval()\n\n    # Make prediction without calculating gradients\n    with torch.no_grad():\n        # Get the model's output\n        output = model(image)\n\n        # Get the predicted class\n        _, predicted_class = torch.max(output, 1)\n\n    # Return the predicted class\n    return predicted_class.item()\n\n# Example usage:\nimage_path = '/kaggle/input/potato-leaf-disease-dataset/Potato Leaf Disease Dataset in Uncontrolled Environment/Fungi/1692332350583.jpg'  # Replace with the path to the image you want to predict\ntransform = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor()\n])\n\npredicted_class = predict_image(image_path, model, transform, device)\nif predicted_class==0:\n    print(f'The predicted class for the given image is: bacteria')\nelif predicted_class==1:\n    print(f'The predicted class for the given image is: fungi')\nelif predicted_class==2:\n    print(f'The predicted class for the given image is: healthy')\nelif predicted_class==3:\n    print(f'The predicted class for the given image is: Nemastode')\nelif predicted_class==4:\n    print(f'The predicted class for the given image is: k')\nelif predicted_class==5:\n    print(f'The predicted class for the given image is: Phytopthora')\nelif predicted_class==6:\n    print(f'The predicted class for the given image is: Virus')\n","metadata":{"id":"T-FO2ALNK61v","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nprint(confusion_matrix(true_labels, predicted_labels))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}